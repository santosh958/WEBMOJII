{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjYjPHVlLIH073xZjYJvbb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santosh958/WEBMOJII/blob/main/scrape_b2b_websites_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YHPxUOB8slP",
        "outputId": "68d31a33-a400-4f09-8c5f-e405a9554561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.6.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import os\n",
        "\n",
        "def safe_get_text(element, default=\"N/A\"):\n",
        "    \"\"\"Safe text extraction from a BeautifulSoup element.\"\"\"\n",
        "    try:\n",
        "        return element.text.strip()\n",
        "    except AttributeError:\n",
        "        return default\n",
        "\n",
        "def scrape_pricing(soup):\n",
        "    \"\"\"Scrape pricing details from a website.\"\"\"\n",
        "    pricing_element = soup.find('div', class_='pricing')  # Adjust this selector based on actual HTML\n",
        "    pricing = pricing_element.text.strip() if pricing_element else 'Pricing not available'\n",
        "    return pricing\n",
        "\n",
        "def scrape_speakers(soup):\n",
        "    \"\"\"Scrape speaker details from a website.\"\"\"\n",
        "    speakers_section = soup.find_all('div', class_='speaker')  # Adjust this selector based on actual HTML\n",
        "    speakers = []\n",
        "    for speaker in speakers_section:\n",
        "        name = safe_get_text(speaker.find('h3', class_='name'))\n",
        "        bio = safe_get_text(speaker.find('p', class_='bio'))\n",
        "        speakers.append({'name': name, 'bio': bio})\n",
        "    return speakers\n",
        "\n",
        "def scrape_blake_envelopes(soup):\n",
        "    \"\"\"Scrape data from Blake Envelopes website.\"\"\"\n",
        "    event_name = safe_get_text(soup.title, \"N/A\")\n",
        "    description = safe_get_text(soup.find(\"meta\", {\"name\": \"description\"}), \"N/A\")\n",
        "    return [event_name, \"N/A\", \"N/A\", description, scrape_speakers(soup), \"N/A\", \"N/A\", scrape_pricing(soup), \"N/A\", \"N/A\"]\n",
        "\n",
        "def scrape_pixelgrade(soup):\n",
        "    \"\"\"Scrape data from Pixelgrade website.\"\"\"\n",
        "    event_name = safe_get_text(soup.title, \"N/A\")\n",
        "    return [event_name, \"N/A\", \"N/A\", \"N/A\", scrape_speakers(soup), \"N/A\", \"N/A\", scrape_pricing(soup), \"N/A\", \"N/A\"]\n",
        "\n",
        "def scrape_dropbox(soup):\n",
        "    \"\"\"Scrape data from Dropbox website.\"\"\"\n",
        "    event_name = safe_get_text(soup.title, \"N/A\")\n",
        "    description = safe_get_text(soup.find(\"meta\", {\"name\": \"description\"}), \"N/A\")\n",
        "    return [event_name, \"N/A\", \"N/A\", description, scrape_speakers(soup), \"N/A\", \"N/A\", scrape_pricing(soup), \"N/A\", \"N/A\"]\n",
        "\n",
        "def scrape_olumo(soup):\n",
        "    \"\"\"Scrape data from Olumo website.\"\"\"\n",
        "    event_name = safe_get_text(soup.title, \"N/A\")\n",
        "    return [event_name, \"N/A\", \"N/A\", \"N/A\", scrape_speakers(soup), \"N/A\", \"N/A\", scrape_pricing(soup), \"N/A\", \"N/A\"]\n",
        "\n",
        "def scrape_trello(soup):\n",
        "    \"\"\"Scrape data from Trello website.\"\"\"\n",
        "    event_name = safe_get_text(soup.title, \"N/A\")\n",
        "    description = safe_get_text(soup.find(\"meta\", {\"name\": \"description\"}), \"N/A\")\n",
        "    return [event_name, \"N/A\", \"N/A\", description, scrape_speakers(soup), \"N/A\", \"N/A\", scrape_pricing(soup), \"N/A\", \"N/A\"]\n",
        "\n",
        "def scrape_website_details(url):\n",
        "    \"\"\"Route scraping tasks to appropriate functions based on URL.\"\"\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    if \"blake-envelopes\" in url:\n",
        "        return scrape_blake_envelopes(soup)\n",
        "    elif \"pixelgrade\" in url:\n",
        "        return scrape_pixelgrade(soup)\n",
        "    elif \"dropbox\" in url:\n",
        "        return scrape_dropbox(soup)\n",
        "    elif \"olumo\" in url:\n",
        "        return scrape_olumo(soup)\n",
        "    elif \"trello\" in url:\n",
        "        return scrape_trello(soup)\n",
        "    else:\n",
        "        return [\"N/A\", \"N/A\", \"N/A\", url, \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\"]\n",
        "\n",
        "# List of URLs to scrape\n",
        "urls = [\n",
        "    \"https://www.blake-envelopes.com\",\n",
        "    \"https://pixelgrade.com\",\n",
        "    \"https://www.dropbox.com/events\",\n",
        "    \"https://www.olumo.com\",\n",
        "    \"https://trello.com\"\n",
        "]\n",
        "\n",
        "# Open CSV file to write the data\n",
        "with open('b2b_websites.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Event Name\", \"Event Dates\", \"Location\", \"Website URL\", \"Description\", \"Key Speakers\", \"Agenda\", \"Registration Details\", \"Pricing\", \"Categories\", \"Audience Type\"])\n",
        "\n",
        "    # Loop through URLs and write details to CSV\n",
        "    for url in urls:\n",
        "        website_details = scrape_website_details(url)\n",
        "        print(f\"Scraped data for {url}: {website_details}\")\n",
        "        writer.writerow([website_details[0], website_details[1], website_details[2], url, website_details[3], website_details[4], website_details[5], website_details[6], website_details[7], website_details[8], website_details[9]])\n",
        "\n",
        "# Verifying the file creation\n",
        "if os.path.exists('b2b_websites.csv'):\n",
        "    print(\"CSV file has been created successfully.\")\n",
        "else:\n",
        "    print(\"CSV file was not created.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhTTczbN83UM",
        "outputId": "9fd06dbc-a291-4711-a6b5-b2a54013668a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped data for https://www.blake-envelopes.com: ['Envelopes & Mailing Supplies - Postal Packaging - Blake Envelopes', 'N/A', 'N/A', '', [], 'N/A', 'N/A', 'Pricing not available', 'N/A', 'N/A']\n",
            "Scraped data for https://pixelgrade.com: ['pixelgrade.com | 520: Web server is returning an unknown error', 'N/A', 'N/A', 'N/A', [], 'N/A', 'N/A', 'Pricing not available', 'N/A', 'N/A']\n",
            "Scraped data for https://www.dropbox.com/events: ['Login - Dropbox', 'N/A', 'N/A', '', [], 'N/A', 'N/A', 'Pricing not available', 'N/A', 'N/A']\n",
            "Scraped data for https://www.olumo.com: ['Olumo | Olumo Uncovers The Real People Problems', 'N/A', 'N/A', 'N/A', [], 'N/A', 'N/A', 'Pricing not available', 'N/A', 'N/A']\n",
            "Scraped data for https://trello.com: ['Manage Your Teamâ€™s Projects From Anywhere | Trello', 'N/A', 'N/A', '', [], 'N/A', 'N/A', 'Pricing not available', 'N/A', 'N/A']\n",
            "CSV file has been created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Assuming 'scrape_b2b_websites.csv' is the file you uploaded\n",
        "file_path = 'b2b_websites.csv'\n",
        "\n",
        "# Create a download link\n",
        "files.download(file_path)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "CQ6EfF3y_Fpt",
        "outputId": "3d8c8950-2dfd-4bce-f4f9-3a8f00cf3640"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3206bafc-e81f-4a50-96a0-e85c14ace29c\", \"b2b_websites.csv\", 765)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}